{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_cleaning\n",
    "# Data Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Machine Learning\n",
    "from sklearn.svm import  SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from custom_confusion_matrix import make_confusion_matrix\n",
    "from scipy.stats import ks_2samp, kstest\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "from scipy.stats.mstats import gmean\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Status\", \"Duration_in_month\", \"Credit_history\", \"Purpose\",\n",
    "        \"Credit_amount\", \"Savings_account\", \"Present_employment_since\", \"Installment_rate\",\n",
    "        \"Personal_status\", \"Other_debtors\", \"Present_residence\", \"Property\",\n",
    "        \"Age\", \"Other_installment\", \"Housing\", \"Number_of_existing_credits\",\n",
    "        \"Job\", \"Number_of_people\", \"Telephone\", \"foreign_worker\", \"pred\"]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"german.data\", delimiter=' ', header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration_in_month</th>\n",
       "      <th>Credit_history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit_amount</th>\n",
       "      <th>Savings_account</th>\n",
       "      <th>Present_employment_since</th>\n",
       "      <th>Installment_rate</th>\n",
       "      <th>Personal_status</th>\n",
       "      <th>Other_debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property</th>\n",
       "      <th>Age</th>\n",
       "      <th>Other_installment</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Number_of_existing_credits</th>\n",
       "      <th>Job</th>\n",
       "      <th>Number_of_people</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Status  Duration_in_month Credit_history Purpose  Credit_amount  \\\n",
       "0    A11                  6            A34     A43           1169   \n",
       "1    A12                 48            A32     A43           5951   \n",
       "2    A14                 12            A34     A46           2096   \n",
       "3    A11                 42            A32     A42           7882   \n",
       "4    A11                 24            A33     A40           4870   \n",
       "\n",
       "  Savings_account Present_employment_since  Installment_rate Personal_status  \\\n",
       "0             A65                      A75                 4             A93   \n",
       "1             A61                      A73                 2             A92   \n",
       "2             A61                      A74                 2             A93   \n",
       "3             A61                      A74                 2             A93   \n",
       "4             A61                      A73                 3             A93   \n",
       "\n",
       "  Other_debtors  ...  Property Age  Other_installment Housing  \\\n",
       "0          A101  ...      A121  67               A143    A152   \n",
       "1          A101  ...      A121  22               A143    A152   \n",
       "2          A101  ...      A121  49               A143    A152   \n",
       "3          A103  ...      A122  45               A143    A153   \n",
       "4          A101  ...      A124  53               A143    A153   \n",
       "\n",
       "  Number_of_existing_credits   Job Number_of_people  Telephone foreign_worker  \\\n",
       "0                          2  A173                1       A192           A201   \n",
       "1                          1  A173                1       A191           A201   \n",
       "2                          1  A172                2       A191           A201   \n",
       "3                          1  A173                2       A191           A201   \n",
       "4                          2  A173                2       A191           A201   \n",
       "\n",
       "  pred  \n",
       "0    1  \n",
       "1    2  \n",
       "2    1  \n",
       "3    1  \n",
       "4    2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"pred\"] = dataframe[\"pred\"].map({1: 0, 2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop([\"pred\"], axis=1)\n",
    "y = dataframe[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700 700]\n",
      "[300 300]\n",
      "[587 300]\n",
      "[700 700]\n",
      "[700 712]\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "print(np.bincount(y_over))\n",
    "undersample=RandomUnderSampler(sampling_strategy='majority')\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "print(np.bincount(y_under))\n",
    "numeric_cols = dataframe.select_dtypes(include='number')\n",
    "X = numeric_cols.drop([\"pred\"], axis=1)\n",
    "y = numeric_cols[\"pred\"]\n",
    "# Apply One-Sided Selection\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "oss.fit(X, y)\n",
    "X_oss, y_oss = oss.fit_resample(X, y)\n",
    "print(np.bincount(y_oss))\n",
    "X_SMOTE, y_SMOTE = SMOTE(k_neighbors=5).fit_resample(X, y)\n",
    "print(np.bincount(y_SMOTE))\n",
    "X_ADASYN, y_ADASYN = ADASYN(n_neighbors=5).fit_resample(X, y)\n",
    "print(np.bincount(y_ADASYN))\n",
    "list_of_X=[X_over,X_under,X_oss,X_SMOTE,X_ADASYN]\n",
    "list_of_y=[y_over,y_under,y_oss,y_SMOTE,y_ADASYN]\n",
    "names = [\"over\",\"under\",\"oss\",\"smote\",\"adasyn\"]\n",
    "resample_dic={}\n",
    "for i in names:\n",
    "    for X,y in zip(list_of_X,list_of_y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y,\n",
    "                                                    shuffle=True)\n",
    "        numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "        numeric_pipeline = Pipeline(steps=[('Scale', MinMaxScaler())])\n",
    "        categorical_pipeline = Pipeline(steps=[('One-Hot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "        full_processor = ColumnTransformer(transformers=[('number', numeric_pipeline, numerical_features),('category', categorical_pipeline, categorical_features)])\n",
    "        X_train_transformed = full_processor.fit_transform(X_train)\n",
    "        X_test_transformed = full_processor.transform(X_test)\n",
    "        corr = spearmanr(X_train_transformed).correlation\n",
    "        corr_linkage = hierarchy.ward(corr)\n",
    "        cluster_ids = hierarchy.fcluster(corr_linkage,2, criterion='distance')\n",
    "        cluster_id_to_feature_ids = defaultdict(list)\n",
    "        for idx, cluster_id in enumerate(cluster_ids):\n",
    "            cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "        selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "        X_train_sel = X_train_transformed[:, selected_features]\n",
    "        X_test_sel = X_test_transformed[:, selected_features]\n",
    "        resample_dic[f\"X_train_transformed-{i}\"] = X_train_sel\n",
    "        resample_dic[f\"X_test_transformed-{i}\"] = X_test_sel\n",
    "        resample_dic[f\"y_train-{i}\"] = y_train\n",
    "        resample_dic[f\"y_test-{i}\"] = y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(C=1.0, kernel='poly', tol=0.001)\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "nb_clf = GaussianNB()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "ann_clf = MLPClassifier(solver='adam', hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\n",
    "list_of_classifiers = [svm_clf,lr_clf,dt_clf,rf_clf,nb_clf,knn_clf,qda_clf,lda_clf,ann_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_classifiers = [\"SVC\", \"LogisticRegression\",\"RandomForestClassifier\",\"DecisionTreeClassifier\", \"GaussianNB\", \"QuadraticDiscriminantAnalysis\",\"LinearDiscriminantAnalysis\", \"MLPClassifier\", \"KNeighborsClassifier\"]\n",
    "y_pred_dic = {}\n",
    "for i in names:\n",
    "    for pred,cname in zip(list_of_classifiers,name_of_classifiers):\n",
    "        #print(i)\n",
    "        pred.fit(resample_dic.get(f\"X_train_transformed-{i}\"),resample_dic.get(f\"y_train-{i}\"))\n",
    "        y_pred = pred.predict(resample_dic.get(f\"X_test_transformed-{i}\"))\n",
    "        y_pred_dic[f\"y_pred_{i}_{cname}\"] = y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification     over under oss smote adasyn\n",
      "\n",
      "dict_values([0.5929342992932694, 0.5929342992932694, 0.5929342992932694, 0.5929342992932694, 0.5929342992932694, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773, 0.6456517757373194, 0.6456517757373194, 0.6456517757373194, 0.6456517757373194, 0.6456517757373194, 0.6266827743827366, 0.6266827743827366, 0.6266827743827366, 0.6266827743827366, 0.6266827743827366, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.6165578357761262, 0.6165578357761262, 0.6165578357761262, 0.6165578357761262, 0.6165578357761262, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.5471216549024156, 0.5386873388894104, 0.5386873388894104, 0.5386873388894104, 0.5386873388894104, 0.5386873388894104, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773, 0.5456458150327773])\n"
     ]
    }
   ],
   "source": [
    "cm_dic = {}\n",
    "for k,cname in zip(y_pred_dic.keys(),name_of_classifiers):\n",
    "    #print(k)\n",
    "    for i in names:\n",
    "        #print(i)\n",
    "        cm = confusion_matrix(resample_dic.get(f\"y_test-{i}\"), y_pred_dic[k])\n",
    "        cm_dic[f\"cm_{i}_{cname}\"] = cm\n",
    "        \n",
    "#print(cm_dic) \n",
    "\n",
    "cm2=[]\n",
    "gmean_dic = {}\n",
    "new_gmean = {}\n",
    "for k in cm_dic.keys():\n",
    "    #print(cm_dic)\n",
    "    cm2 = cm_dic[k]\n",
    "    TP = cm2[0][0]\n",
    "    FN = cm2[1][0]\n",
    "    FP = cm2[0][1]\n",
    "    TN = cm2[1][1]\n",
    "    TPR=TP/(TP+FN)\n",
    "    TNR=TN/(TN+FP)\n",
    "    AUC=(TPR+TNR)/2\n",
    "    precision = TP/(TP+FP)\n",
    "    arr1 = gmean([TPR,TNR])\n",
    "    gmean_dic[f\"gmean_{k}\"] =arr1\n",
    "    #(1+0.05*(TPR-TNR))*math.sqrt(TPR*TNR)\n",
    "\n",
    "key_list = list(gmean_dic.keys())\n",
    "value_list=list(gmean_dic.values())\n",
    "print('classification    ',*names)\n",
    "print()\n",
    "svm_key_list=key_list[0:5]\n",
    "svm_value_list=value_list[0:5]\n",
    "#print(svm_value_list)\n",
    "#print(svm_key_list)\n",
    "print(gmean_dic.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62bf3cc52dd2c8551036d06522b00ae3d9933b656a5d7f5cc9ec6492506cc1b9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
